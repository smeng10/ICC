{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1\n",
    "firstly, a list which contains weights is given. You need to load the weight into the model correctly. Then test the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weights_list is the parameter sets of the networks\n",
    "\n",
    "It's structure is like:\n",
    "[\n",
    "[],\n",
    "[layer a's weights, layer a's bias,...],\n",
    "[layer b's weights]\n",
    "]\n",
    "'''\n",
    "import pickle\n",
    "with open ('params_sets', 'rb') as fp:\n",
    "    weights_list = pickle.load(fp,encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is the model for the testing part\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    #first dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(48,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #second dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(96,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #third dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(192,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #fourth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(384,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #fifth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(512,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #output\n",
    "    layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The function is to convert the image into the input type.\n",
    "'''\n",
    "def load_input(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((320,160))\n",
    "    input_img = np.asarray(img).astype(np.float32)\n",
    "    input_img = (input_img/255 - 0.5)/0.25\n",
    "    return input_img[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the function to get the predict box (x,y,w,h)\n",
    "'''\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def get_box(output):\n",
    "    anchors = [1.4940052559648322, 2.3598481287086823, 4.0113013115312155, 5.760873975661669]\n",
    "    h = output.shape[2]\n",
    "    w = output.shape[3]\n",
    "    output = output.reshape(2,5,800).transpose(1,0,2).flatten().reshape(5,1600)\n",
    "    grid_x = np.tile(np.tile(np.linspace(0,w-1,w),h).reshape(h,w),(2,1,1)).flatten()\n",
    "    grid_y =np.tile(np.tile(np.linspace(0,h-1,h),w).reshape(w,h).T,(2,1,1)).flatten()\n",
    "    xs = sigmoid(output[0]) + grid_x\n",
    "    ys = sigmoid(output[1]) + grid_y\n",
    "    anchor_w = np.zeros(1600)\n",
    "    anchor_h = np.zeros(1600)\n",
    "    anchor_w[0:800] = anchors[0]\n",
    "    anchor_w[800:1600] = anchors[2]\n",
    "    anchor_h[0:800] = anchors[1]\n",
    "    anchor_h[800:1600] = anchors[3]\n",
    "    ws = np.exp(output[2]) * anchor_w\n",
    "    hs = np.exp(output[3]) * anchor_h\n",
    "    ind = np.argmax(output[4])\n",
    "    bcx = xs[ind]\n",
    "    bcy = ys[ind]\n",
    "    bw = ws[ind]\n",
    "    bh = hs[ind]\n",
    "    box = [bcx/w, bcy/h, bw/w, bh/h]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = load_input('images/2.jpg')\n",
    "output = model.predict(input_img).transpose(0,3,1,2)\n",
    "count = 1\n",
    "for i in model.layers:\n",
    "    if i.get_config()['name'].startswith('re_lu') or i.get_config()['name'].startswith('max_pooling'):\n",
    "        continue\n",
    "    else:\n",
    "        i.set_weights(weights_list[count])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the cell to test your weights correctness.\n",
    "\n",
    "The output should be :\n",
    "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "output = model.predict(input_img).transpose(0,3,1,2)\n",
    "print (get_box(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now finish the function to compute the iou between two given box.\n",
    "\n",
    "You can refer to the website: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "'''\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    '''your code here'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given dataset compute the iou\n",
    "'''\n",
    "import json\n",
    "with open('groundtruth.txt', 'r') as outfile:\n",
    "    lines = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cdf699f70f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdetectiongt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m cv2.rectangle(image, tuple(detectiongt[:2]), \n\u001b[1;32m----> 8\u001b[1;33m     tuple(detectiongt[2:]), (0, 255, 0), 2)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdetectionpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m cv2.rectangle(image, tuple(detectionpred[:2]), \n",
      "\u001b[1;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(lines[0][0])\n",
    " \n",
    "# draw the ground-truth bounding box along with the predicted\n",
    "# bounding box\n",
    "detectiongt = lines[0][1]\n",
    "cv2.rectangle(image, tuple(detectiongt[:2]), \n",
    "    tuple(detectiongt[2:]), (0, 255, 0), 2)\n",
    "detectionpred = get_box(model.predict(input_img).transpose(0,3,1,2))\n",
    "cv2.rectangle(image, tuple(detectionpred[:2]), \n",
    "    tuple(detectionpred[2:]), (0, 0, 255), 2)\n",
    "\n",
    "# compute the intersection over union and display it\n",
    "iou = bbox_iou(detectiongt, detectionpred)\n",
    "cv2.putText(image, \"IoU: {:.4f}\".format(iou), (10, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "print(\"{}: {:.4f}\".format(image, iou))\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951736822400643\n",
      "0.94857064779409\n",
      "0.9731527700341455\n",
      "0.9750984926117859\n",
      "0.9905525351305893\n",
      "0.954411112492113\n",
      "0.9794809880013137\n",
      "0.97068124313231\n",
      "0.9813808443399756\n",
      "0.9884230068533355\n",
      "0.9165642034672067\n",
      "0.9827304611644302\n",
      "0.9608683145972255\n",
      "0.9724563039712526\n",
      "0.9592606062752358\n",
      "0.9602515675961311\n",
      "0.8370722604767621\n",
      "0.9464989204087023\n",
      "0.8796097533518571\n",
      "0.8887995804726144\n",
      "0.9630095437439465\n",
      "0.9197719179452705\n",
      "0.979321499880439\n",
      "0.9800708111798213\n",
      "0.986229694298195\n",
      "0.8488353508130956\n",
      "0.9728128619208227\n",
      "0.5541060130224168\n",
      "0.9834891662016207\n",
      "0.977670216276692\n",
      "0.8898355358128887\n",
      "0.9749107408432032\n",
      "0.9702762821334907\n",
      "0.4924885855838093\n",
      "0.8030788886829884\n",
      "0.9098996133582014\n",
      "0.9596904537985328\n",
      "0.9605413735970415\n",
      "0.6093458582085839\n",
      "0.19051099006511052\n",
      "0.9703568882910256\n",
      "0.43623071390306173\n",
      "0.9280485307980458\n",
      "0.9353907888918831\n",
      "0.8265670151638929\n",
      "0.9740813591506317\n",
      "0.9035519237618067\n",
      "0.921936466263269\n",
      "0.9395662787803205\n",
      "0.7184306878686398\n",
      "0.8494773136398805\n",
      "0.3731649707201902\n",
      "0.9544141991661504\n",
      "0.9854493610698892\n",
      "0.32460198140864244\n",
      "0.9513401746514085\n",
      "0.9084273377676503\n",
      "0.9862346303466151\n",
      "0.928386563039793\n",
      "0.9776685698909097\n",
      "0.9757633606969927\n",
      "0.9486709117880218\n",
      "0.9780982626481963\n",
      "0.9669437300865781\n",
      "0.9259333410221352\n",
      "0.9513806473162345\n",
      "0.733250926786496\n",
      "0.968329351707474\n",
      "0.9755543340840764\n",
      "0.9766293148404116\n",
      "0.9877207157317425\n",
      "0.9733024788820079\n",
      "0.9642459380179786\n",
      "0.9895516025613371\n",
      "0.9183695874168013\n",
      "0.933356243053397\n",
      "0.9585534073531864\n",
      "0.2676483525474087\n",
      "0.9565136750223355\n",
      "0.9609963743508315\n",
      "0.9801093625351515\n",
      "0.9673490695230719\n",
      "0.987035615890342\n",
      "0.9940286919570565\n",
      "0.946583896124987\n",
      "0.43660135487186136\n",
      "0.9691895128531075\n",
      "0.8885269139501719\n",
      "0.9790435116773571\n",
      "0.9526348224165684\n",
      "0.9144835836180237\n",
      "0.9119643423946485\n",
      "0.8921485779990879\n",
      "0.8483704249940553\n",
      "0.9452452403269048\n",
      "0.987286127729879\n",
      "0.9746421433121765\n",
      "0.9475935769882426\n",
      "0.9653184467803778\n",
      "0.9623233069318221\n",
      "0.9820398370908112\n",
      "0.9835350445882526\n",
      "0.8929178427413682\n",
      "0.7913313311297613\n",
      "0.2172281368120996\n",
      "0.8541815619083181\n",
      "0.9703007017546226\n",
      "0.9811910540183257\n",
      "0.9749739215235704\n",
      "0.8981153753285043\n",
      "0.9835566349781526\n",
      "0.9740290578953776\n",
      "0.9904685628783485\n",
      "0.9377195525396467\n",
      "0.9729631735316133\n",
      "0.9695921311534615\n",
      "0.9870825511628266\n",
      "0.976560571388653\n",
      "0.9673204926439164\n",
      "0.9700165687711664\n",
      "0.9792295443300899\n",
      "0.9793373854149474\n",
      "0.9324540038063962\n",
      "0.9653501228499833\n",
      "0.9475715604514572\n",
      "0.8791837311419441\n",
      "0.9664543418233307\n",
      "0.9611019611939828\n",
      "0.9323655392277233\n",
      "0.9306023985907499\n",
      "0.9817313196230704\n",
      "0.962575642049661\n",
      "0.9620209647958442\n",
      "0.9598545497509184\n",
      "0.9640711590023503\n",
      "0.9536991099856893\n",
      "0.9502235521789123\n",
      "0.9390368191091715\n",
      "0.9412412879670926\n",
      "0.5930174454829388\n",
      "0.9477586702614865\n",
      "0.9695360533023265\n",
      "0.955932550277343\n",
      "0.1676881635356146\n",
      "0.9306793383879317\n",
      "0.9568135869736619\n",
      "0.9909198218591637\n",
      "0.9642833488262608\n",
      "0.9882753318349746\n",
      "0.704354530860981\n",
      "0.9774456008313492\n",
      "0.9591290265859219\n",
      "0.41333016957546626\n",
      "0.7057150015185574\n",
      "0.3721129998681838\n",
      "0.9671412386880832\n",
      "0.9409631631206605\n",
      "0.9520637343591775\n",
      "0.9676999762448413\n",
      "0.7403620583889683\n",
      "0.9803325833416566\n",
      "0.9700011741913582\n",
      "0.920907353951243\n",
      "0.34981173194610454\n",
      "0.9757158564618033\n",
      "0.9832702189253244\n",
      "0.9211185666451619\n",
      "0.976221408620466\n",
      "0.9683196243446852\n",
      "0.9460022327946964\n",
      "0.9544195747157546\n",
      "0.9430166745939091\n",
      "0.9259596924219081\n",
      "0.9694536189728723\n",
      "0.9850450860365232\n",
      "0.9594234972901154\n",
      "0.9881585242947918\n",
      "0.9700718970484301\n",
      "0.9697260100177378\n",
      "0.5802605817307657\n",
      "0.9861868962489335\n",
      "0.9477644541354232\n",
      "0.9633748243639824\n",
      "0.966995960556027\n",
      "0.9852310576271994\n",
      "0.9611028445651839\n",
      "0.977637086766403\n",
      "0.9756831181696118\n",
      "0.9442358290959222\n",
      "0.9670886070976867\n",
      "0.9965971934679789\n",
      "0.9712187720172549\n",
      "0.9221199945209526\n",
      "0.9823312006995037\n",
      "0.35777134430666235\n",
      "0.9786656901245174\n",
      "0.9354061304670633\n",
      "0.9774177731016144\n",
      "0.9052670677133621\n",
      "0.9764931200414625\n",
      "0.978103309440464\n",
      "0.18971410286193208\n",
      "0.9724609376533432\n",
      "0.9570475401867675\n",
      "0.9224956292562484\n",
      "0.9413986997934196\n",
      "0.9601639487383327\n",
      "0.9316001857476929\n",
      "0.9568115181938998\n",
      "0.9090530902054781\n",
      "0.9590151523400959\n",
      "0.8724049559080198\n",
      "0.9693782406750165\n",
      "0.9651313505340645\n",
      "0.9635532940849593\n",
      "0.9254560643970424\n",
      "0.967801028614807\n",
      "0.9834020734071673\n",
      "0.9878296151906405\n",
      "0.9349165214055918\n",
      "0.9627370666463207\n",
      "0.9687334926298657\n",
      "0.9748499113819773\n",
      "0.9777053000748289\n",
      "0.9838927354342245\n",
      "0.9789721635984453\n",
      "0.8948522304594626\n",
      "0.9450132116582324\n",
      "0.9249129976089012\n",
      "0.9682097560825178\n",
      "0.9737116869493697\n",
      "0.9757746010681865\n",
      "0.9600586759591806\n",
      "0.9429096363461976\n",
      "0.9471227795249663\n",
      "0.9866934289471915\n",
      "0.9692270483108927\n",
      "0.9833170327511752\n",
      "0.9715120803369311\n",
      "0.9415032929141187\n",
      "0.9539927483213134\n",
      "0.9722560156954879\n",
      "0.980747945535217\n",
      "0.9858986716317332\n",
      "0.9830623818057435\n",
      "0.9620059098840761\n",
      "0.980083472177547\n",
      "0.9446282450312188\n",
      "0.9518319682796037\n",
      "0.9289561237547412\n",
      "0.968939161290338\n",
      "0.9177875306967558\n",
      "0.36398858268311324\n",
      "0.9554700321281824\n",
      "0.9607257255528793\n",
      "0.9868447953717844\n",
      "0.9527883486062866\n",
      "0.97457089324057\n",
      "0.6651853396718868\n",
      "0.9607794186744751\n",
      "0.6475684337602596\n",
      "0.9667301070252411\n",
      "0.9134645428378646\n",
      "0.9742347829043638\n",
      "0.9680949022482793\n",
      "0.34525495140582796\n",
      "0.9492515255350794\n",
      "0.9774859011621471\n",
      "0.9225547018853494\n",
      "0.9665860456435736\n",
      "0.9608875830048385\n",
      "0.6116990873591083\n",
      "0.8578217514258384\n",
      "0.9859218373181028\n",
      "0.9870047090146516\n",
      "0.924325637950555\n",
      "0.9682249058773605\n",
      "0.2651472980965403\n",
      "0.9930941698526785\n",
      "0.9773182365287744\n",
      "0.9789180706865926\n",
      "0.9792118687719317\n",
      "0.9619887755333695\n",
      "0.9750041129081104\n",
      "0.9804517656865416\n",
      "0.42624856819983914\n",
      "0.9629678162099493\n",
      "0.926705323330056\n",
      "0.20548176470084947\n",
      "0.8525584384431344\n",
      "0.9345817050983026\n",
      "0.9700894129400214\n",
      "0.9590812250208427\n",
      "0.8370966811959759\n",
      "0.9365792465666498\n",
      "0.9758453549869562\n",
      "0.9317183873050953\n",
      "0.9803951806412537\n",
      "0.9701647278497146\n",
      "0.9571034297449722\n",
      "0.9498960114576404\n",
      "0.9737841134349964\n",
      "0.9699576112078988\n",
      "0.9802179043056386\n",
      "0.9393137539673084\n",
      "0.9261655939008503\n",
      "0.957196876241344\n",
      "0.9772966225642433\n",
      "0.9581963670224035\n",
      "0.985900324305155\n",
      "0.9510857305317103\n",
      "0.6534383515816559\n",
      "0.9630809293930639\n",
      "0.9361794806208581\n",
      "0.971118302612175\n",
      "0.9631386745621306\n",
      "0.9820365848531128\n",
      "0.9722575901087311\n",
      "0.9705082923066064\n",
      "0.9744634670293654\n",
      "0.9495256324820758\n",
      "0.97902968367221\n",
      "0.9615191379951467\n",
      "0.9555786408002108\n",
      "0.9407904164847302\n",
      "0.9919448635230902\n",
      "0.9557333430620581\n",
      "0.8926357468393008\n",
      "0.9507811917264613\n",
      "0.21747383603647438\n",
      "0.9369042563015472\n",
      "0.9869632667235249\n",
      "0.9706578337581413\n",
      "0.9264582315773778\n",
      "0.97761929136514\n",
      "0.9509161522138393\n",
      "0.9700143689651245\n",
      "0.9498263434278934\n",
      "0.9910080167005861\n",
      "0.9484174102178963\n",
      "0.9651381765763255\n",
      "0.9809994127607911\n",
      "0.9304661497155232\n",
      "0.9018302412046911\n",
      "0.9496916946574478\n",
      "0.9739105974096341\n",
      "0.9108786398652952\n",
      "0.9616533217307809\n",
      "0.9701486206098681\n",
      "0.9764783656506881\n",
      "0.8659313203295662\n",
      "0.9641696696978002\n",
      "0.9578264197283316\n",
      "0.8717819685397808\n",
      "0.9484179956966543\n",
      "0.9873735660449308\n",
      "0.9765218206318851\n",
      "0.9683598659307119\n",
      "0.9865384148631493\n",
      "0.9798641666759977\n",
      "0.9564387615253664\n",
      "0.9137838126392177\n",
      "0.9831394885197452\n",
      "0.8860789602366571\n",
      "0.9669646873828821\n",
      "0.9771341198283435\n",
      "0.9342778287902243\n",
      "0.9478908497104329\n",
      "0.8966814321279518\n",
      "0.9743840348538816\n",
      "0.9500981270347131\n",
      "0.9832585895662541\n",
      "0.9338859925021924\n",
      "0.3084873308685889\n",
      "0.9566266201954252\n",
      "0.9536720732490179\n",
      "0.9812008948025513\n",
      "0.9664757998034379\n",
      "0.38430437965964875\n",
      "0.9807161491057445\n",
      "0.9469404258538153\n",
      "0.35937770532034674\n",
      "0.9392041750387529\n",
      "0.9278612354495646\n",
      "0.7043807446677448\n",
      "0.9841288801133673\n",
      "0.8609169352139711\n",
      "0.9694554413180798\n",
      "0.9781629881896714\n",
      "0.9862471639952394\n",
      "0.9459692423943309\n",
      "0.9434658547010668\n",
      "0.9288939290647036\n",
      "0.9412073998922761\n",
      "0.9741708062869806\n",
      "0.9704121859116744\n",
      "0.9722094579865734\n",
      "0.9682319585673571\n",
      "0.3493761840654924\n",
      "0.957237094696329\n",
      "0.9553110470653057\n",
      "0.960610104816576\n",
      "0.9285020508661045\n",
      "0.8975118657124801\n",
      "0.9517901753079306\n",
      "0.9383817544264318\n",
      "0.9579888846716775\n",
      "0.9715011482459827\n",
      "0.9485432974937246\n",
      "0.9758728775642086\n",
      "0.9754681587489361\n",
      "0.9906634719091679\n",
      "0.41123072933728416\n",
      "0.9639660247346867\n",
      "0.9787282931944643\n",
      "0.9520635895345595\n",
      "0.920362433782169\n",
      "0.9761588001556624\n",
      "0.9760352862132843\n",
      "0.9684964383532262\n",
      "0.9791995841800656\n",
      "0.93107803889495\n",
      "0.9550686771710379\n",
      "0.9450220943037613\n",
      "0.9835088183864933\n",
      "0.9844033168732835\n",
      "0.9268328904350652\n",
      "0.9845788898217055\n",
      "0.9670029887354189\n",
      "0.9653204716918528\n",
      "0.9759136076376205\n",
      "0.9590865611452398\n",
      "0.9734563891707738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9721788948653858\n",
      "0.6412786473523674\n",
      "0.8712519881504597\n",
      "0.9812635044222847\n",
      "0.9635622636974553\n",
      "0.9614945019763463\n",
      "0.9489137590427311\n",
      "0.9457191419584171\n",
      "0.9567697672560623\n",
      "0.9322479295648619\n",
      "0.9584117915213979\n",
      "0.2880343182689145\n",
      "0.975559522832453\n",
      "0.985055877893315\n",
      "0.9798406202723013\n",
      "0.9823604327684624\n",
      "0.9660781780116827\n",
      "0.9294249726435984\n",
      "0.9842730899119315\n",
      "0.9409003406441222\n",
      "0.9667366322764708\n",
      "0.876502904925786\n",
      "0.9695944897249075\n",
      "0.9846655364493687\n",
      "0.941608069801656\n",
      "0.9586075543564752\n",
      "0.9604897575291624\n",
      "0.9784252123657409\n",
      "0.9636077689650908\n",
      "0.19590255476226817\n",
      "0.9260396590840859\n",
      "0.9620875424852185\n",
      "0.94725382752145\n",
      "0.9866804036455173\n",
      "0.9244108407353578\n",
      "0.9556003609612739\n",
      "0.9903430178678292\n",
      "0.958157402669828\n",
      "0.9842082197293406\n",
      "0.9721621052064755\n",
      "0.9059229614768518\n",
      "0.9603495893951778\n",
      "0.9674615310569428\n",
      "0.960832366294982\n",
      "0.9915002993022131\n",
      "0.984956250583533\n",
      "0.9717782365565569\n",
      "0.30610771698978506\n",
      "0.9258556694749203\n",
      "0.8915899689351864\n",
      "0.5808709779785043\n",
      "0.907926692597654\n",
      "0.9512942469199335\n",
      "0.9688593668890575\n",
      "0.9824063472838227\n",
      "0.9861449825281624\n",
      "0.9169013281422251\n",
      "0.9772471489440149\n",
      "0.9542401633541098\n",
      "0.9723511819009941\n",
      "0.916669589670563\n",
      "0.9705425712671015\n",
      "0.9730162278071979\n",
      "0.9855415191170053\n",
      "0.9379200674888426\n",
      "0.9887848100882928\n",
      "0.9394632804318835\n",
      "0.928085077379044\n",
      "0.9603494643748869\n",
      "0.9354778874284874\n",
      "0.9729081484572337\n",
      "0.9622308176612108\n",
      "0.8061999902545364\n",
      "0.9821354006471248\n",
      "0.9805410235415954\n",
      "0.9566131354835072\n",
      "0.9622154208558176\n",
      "0.9522740180796172\n",
      "0.9406228335563318\n",
      "0.9691017346584461\n",
      "0.9623025604106125\n",
      "0.9785979290492943\n",
      "0.5264012757640432\n",
      "0.9510732659926003\n",
      "0.982930652908469\n",
      "0.9608042476135121\n",
      "0.9661786601778289\n",
      "0.9393773013007448\n",
      "0.948348620475461\n",
      "0.982968722266391\n",
      "0.4095717469079555\n",
      "0.9744463785758383\n",
      "0.9710251750173834\n",
      "0.9145169332865353\n",
      "0.8646237414184029\n",
      "0.9045538367033913\n",
      "0.9320961524698296\n",
      "0.9663976989872279\n",
      "0.972063824320045\n",
      "0.9855795662787658\n",
      "0.968720859205607\n",
      "0.5550063955354292\n",
      "0.974763591001778\n",
      "0.966017194992617\n",
      "0.9752314341528703\n",
      "0.9416029668419525\n",
      "0.9229307771609764\n",
      "0.9316419887201951\n",
      "0.31207212970132614\n",
      "0.9770212349253551\n",
      "0.9570266781883349\n",
      "0.9480316896369715\n",
      "0.9796810117037962\n",
      "0.9541000549541386\n",
      "0.9416869395684774\n",
      "0.9714563124720307\n",
      "0.9607342417492861\n",
      "0.9674805052578191\n",
      "0.9565834993758257\n",
      "0.9764650860334271\n",
      "0.9862064748122784\n",
      "0.9668339693056752\n",
      "0.9556144956387321\n",
      "0.96152755048288\n",
      "0.38295816135403776\n",
      "0.9769422104376019\n",
      "0.9286548194824265\n",
      "0.9800796169835212\n",
      "0.976094641154719\n",
      "0.976397049963863\n",
      "0.9644808075459306\n",
      "0.9777208032677382\n",
      "0.9882439079325559\n",
      "0.9211786571085351\n",
      "0.9598478531002861\n",
      "0.9323182263328433\n",
      "0.957281337092369\n",
      "0.9337887462399731\n",
      "0.9771158022057603\n",
      "0.9775193203150557\n",
      "0.9702711360470496\n",
      "0.9258114408507762\n",
      "0.9215317221816678\n",
      "0.8387539774851434\n",
      "0.9359015296994259\n",
      "0.9492272675089541\n",
      "0.974971540364628\n",
      "0.9472435251182708\n",
      "0.9704840662085209\n",
      "0.9340018364095192\n",
      "0.9578922547925768\n",
      "0.9195707592569731\n",
      "0.9771030598608057\n",
      "0.9659289158376987\n",
      "0.9875947358007588\n",
      "0.9872966261735948\n",
      "0.9672534715993154\n",
      "0.926832525078262\n",
      "0.9715223452192446\n",
      "0.9792715578095367\n",
      "0.9583218359256636\n",
      "0.22885929182905898\n",
      "0.9709731336222601\n",
      "0.9440652876538068\n",
      "0.9778429975364711\n",
      "0.9627447245591023\n",
      "0.9723817164523235\n",
      "0.9556173278272586\n",
      "0.3266058548692074\n",
      "0.9710800797424591\n",
      "0.41627691000929967\n",
      "0.897894326250699\n",
      "0.9395604052326575\n",
      "0.9691108566090396\n",
      "0.9514415710990626\n",
      "0.5257821350356099\n",
      "0.9742189438297547\n",
      "0.4898866508103495\n",
      "0.9634479510939264\n",
      "0.9860516294238751\n",
      "0.9532540046355891\n",
      "0.9822745476497028\n",
      "0.946672346111937\n",
      "0.9893376514193499\n",
      "0.9783281915832693\n",
      "0.778060921001375\n",
      "0.9808486601504897\n",
      "0.9255431808432748\n",
      "0.7243339605356518\n",
      "0.9816569936025812\n",
      "0.9420116920880706\n",
      "0.975361442905554\n",
      "0.9626798030216156\n",
      "0.9133934421214243\n",
      "0.9691662826798605\n",
      "0.9647850346295525\n",
      "0.959467632916432\n",
      "0.97076520002007\n",
      "0.7489659741093774\n",
      "0.9598825070332252\n",
      "0.9882772929248845\n",
      "0.9783696199471777\n",
      "0.3227887267915356\n",
      "0.9709466525364305\n",
      "0.9569448864952566\n",
      "0.965862754978139\n",
      "0.966723794125954\n",
      "0.9126362606833652\n",
      "0.9700984724338215\n",
      "0.19769833328740008\n",
      "0.8584695315011548\n",
      "0.8273012194808297\n",
      "0.9799350370738595\n",
      "0.8115995055456814\n",
      "0.9766802081053874\n",
      "0.9694761622155985\n",
      "0.9837305234416325\n",
      "0.9341212402208441\n",
      "0.9710222118905103\n",
      "0.9583053211806617\n",
      "0.9765279150899643\n",
      "0.9665161157970735\n",
      "0.9724973031593623\n",
      "0.9765432382709239\n",
      "0.9330914091425434\n",
      "0.9715057856329351\n",
      "0.8697595312733698\n",
      "0.9215802343448015\n",
      "0.9637844833626388\n",
      "0.9509032836154027\n",
      "0.9680802008496483\n",
      "0.9521772471878028\n",
      "0.9590060724482468\n",
      "0.9656799773687995\n",
      "0.9627177796423652\n",
      "0.9270511922070637\n",
      "0.43902405061096333\n",
      "0.956065803090241\n",
      "0.9830378460351277\n",
      "0.9142476918487141\n",
      "0.9853417260008385\n",
      "0.9693144984983422\n",
      "0.9902886824134589\n",
      "0.9618279557925329\n",
      "0.969803894939088\n",
      "0.957653444375394\n",
      "0.9619673493471005\n",
      "0.964313735073374\n",
      "0.2154374035555196\n",
      "0.9619086106391758\n",
      "0.9849955953416141\n",
      "0.9705486610278218\n",
      "0.8510492113809104\n",
      "0.7578464884008705\n",
      "0.9252958839177279\n",
      "0.980469415832927\n",
      "0.6857219414231608\n",
      "0.9532272507078465\n",
      "0.9721074067634811\n",
      "0.9836333457013522\n",
      "0.08994121382304135\n",
      "0.969523257009933\n",
      "0.9580379549302147\n",
      "0.968347489616347\n",
      "0.9707023125894682\n",
      "0.9839425614472861\n",
      "0.992337375661338\n",
      "0.9752545236455363\n",
      "0.9522334598111797\n",
      "0.8751048862469043\n",
      "0.9435602656992798\n",
      "0.967106574074665\n",
      "0.9816700291769025\n",
      "0.9057171787309898\n",
      "0.9548869965922969\n",
      "0.8905314422836307\n",
      "0.9674547160688685\n",
      "0.9243652838176786\n",
      "0.9721431749697418\n",
      "0.9298660475750892\n",
      "0.9584516720828836\n",
      "0.5453624091517465\n",
      "0.9493028660421529\n",
      "0.963317601994065\n",
      "0.9841775874579924\n",
      "0.958941504039097\n",
      "0.9537122786271388\n",
      "0.9744076302090529\n",
      "0.9109090341981072\n",
      "0.9779146106776953\n",
      "0.9185512680539154\n",
      "0.9817793297549344\n",
      "0.9681569612231685\n",
      "0.962964678641391\n",
      "0.9424761596911908\n",
      "0.9914574440990429\n",
      "0.9389022786417408\n",
      "0.948938662071483\n",
      "0.9260190107333809\n",
      "0.9763153103337633\n",
      "0.9540001857745939\n",
      "0.9895616568301151\n",
      "0.9369228019893581\n",
      "0.9876599625061758\n",
      "0.931503193470492\n",
      "0.8798601789845594\n",
      "0.9448224022511384\n",
      "0.9468395251068574\n",
      "0.9493422128612236\n",
      "0.9364315086380577\n",
      "0.8674141036767944\n",
      "0.9430928967652227\n",
      "0.7951122003210206\n",
      "0.9663502765804014\n",
      "0.9761145345154976\n",
      "0.9527213690356229\n",
      "0.9372642256900352\n",
      "0.9692895298441994\n",
      "0.9741698211368888\n",
      "0.9500695270825849\n",
      "0.9648879978873808\n",
      "0.9398319470860479\n",
      "0.9588531312127289\n",
      "0.3167041493493787\n",
      "0.9744776452176501\n",
      "0.929796982861567\n",
      "0.48255932218214187\n",
      "0.9385429759195184\n",
      "0.9789244085827267\n",
      "0.9715092464050739\n",
      "0.9574540555785084\n",
      "0.9568286093408741\n",
      "0.9796470502865943\n",
      "0.9669912627678958\n",
      "0.8926538945056058\n",
      "0.9717601212578763\n",
      "0.9314036507883788\n",
      "0.9691099231081713\n",
      "0.9692793891299781\n",
      "0.9335629529488999\n",
      "0.9803543366015994\n",
      "0.9583985744113076\n",
      "0.9605998643489474\n",
      "0.9625719203001565\n",
      "0.45205775520776875\n",
      "0.9728283757621027\n",
      "0.8405012529160673\n",
      "0.5704944922622641\n",
      "0.8732392501252646\n",
      "0.5982560093234995\n",
      "0.971180306134586\n",
      "0.9694441786519651\n",
      "0.9618035449594498\n",
      "0.9590338787332813\n",
      "0.9587528990821608\n",
      "0.5699346517727955\n",
      "0.4879436808100145\n",
      "0.9412674814846241\n",
      "0.9235259928981205\n",
      "0.9472752744158882\n",
      "0.9064958423698102\n",
      "0.9787127821708421\n",
      "0.9547925741978659\n",
      "0.9613108894284086\n",
      "0.9796679339133021\n",
      "0.9635389748653013\n",
      "0.967621434166108\n",
      "0.9232591053590198\n",
      "0.3300503581165386\n",
      "0.9530118596319953\n",
      "0.9643702933743222\n",
      "0.9730530446411576\n",
      "0.9794158679986043\n",
      "0.9864498805705615\n",
      "0.9332602394759502\n",
      "0.9235074077173645\n",
      "0.965018702063709\n",
      "0.9673049644186933\n",
      "0.974505608318481\n",
      "0.9566067914845341\n",
      "0.7392084100857098\n",
      "0.9162352525520245\n",
      "0.9732161420546294\n",
      "0.589058329068378\n",
      "0.9715301993419251\n",
      "0.9403162672156051\n",
      "0.9678207245557463\n",
      "0.4069834852362506\n",
      "0.9875520768808245\n",
      "0.9549305327295291\n",
      "0.9558809846473966\n",
      "0.9540876337593779\n",
      "0.3737944550430015\n",
      "0.9359360731788373\n",
      "0.9880858387990477\n",
      "0.9379022030942954\n",
      "0.9863526542810044\n",
      "0.9118983871795899\n",
      "0.5226499643542933\n",
      "0.3253708225742571\n",
      "0.9457716987887025\n",
      "0.9917776005745812\n",
      "0.9547755151899936\n",
      "0.9125593624675834\n",
      "0.9594041972699394\n",
      "0.9843400959215304\n",
      "0.97650101031938\n",
      "0.9503885411579924\n",
      "0.9673738247351504\n",
      "0.9584589482166078\n",
      "0.9725263283914751\n",
      "0.9805541021001634\n",
      "0.3741279723219236\n",
      "0.945090947681604\n",
      "0.9637619563436974\n",
      "0.9811888838740612\n",
      "0.9808774173576754\n",
      "0.9813357207245523\n",
      "0.9433441577556333\n",
      "0.9699687737372887\n",
      "0.6768424665990438\n",
      "0.9484826164753264\n",
      "0.9477822623840922\n",
      "0.9075011766427505\n",
      "0.9833417449532189\n",
      "0.9717432873358227\n",
      "0.955780995135057\n",
      "0.9755173678041267\n",
      "0.9787527688157925\n",
      "0.9871452448008364\n",
      "0.9539918819337848\n",
      "0.9270754319478014\n",
      "0.9012971475102572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6989810895570707\n",
      "0.9698829090804983\n",
      "0.9446901953643277\n",
      "0.8850169149024024\n",
      "0.7535910605639887\n",
      "0.6588624858639909\n",
      "0.9667470497081498\n",
      "0.2569778320991741\n",
      "0.11739378664311746\n",
      "0.9802154481940043\n",
      "0.16716541877347413\n",
      "0.9557291072218297\n",
      "0.9388984089695135\n",
      "0.1832644186215246\n",
      "0.9354466941147261\n",
      "0.986536646361984\n",
      "0.8336245178042997\n",
      "0.9410148410601996\n",
      "0.934907004708337\n",
      "0.8848566700066961\n",
      "0.9579251540398613\n",
      "0.9318106316090231\n",
      "0.8837153575193523\n",
      "0.9243296100033457\n",
      "0.9466360455643366\n",
      "0.9863338825999626\n",
      "0.9154852865750407\n",
      "0.9591993281114072\n",
      "0.9820021769541818\n",
      "0.9698308465014125\n",
      "0.9676320643426416\n",
      "0.9474478801379278\n",
      "0.9813258925783586\n",
      "0.9143617023117515\n",
      "0.37769349147352393\n",
      "0.9777075195490021\n",
      "0.9319479292562984\n",
      "0.31181770231656897\n",
      "0.8542546640692179\n",
      "0.9707569550211104\n",
      "0.985061990606539\n",
      "0.9264141541980637\n",
      "0.9578263502443928\n",
      "0.2826467697842283\n",
      "0.9202394429812841\n",
      "0.2899886431942622\n",
      "0.9245417475387677\n",
      "0.9756758434131297\n",
      "0.9832345861076061\n",
      "0.9446512486644988\n",
      "0.9707752983638954\n",
      "0.9263776539166743\n",
      "0.9664509309322363\n",
      "0.9899122117111637\n",
      "0.9786703762187074\n",
      "0.9853455816464262\n",
      "0.9694875549742217\n",
      "0.24809380444889229\n",
      "0.9765992735629024\n",
      "0.9560254827373821\n",
      "0.9666538701016291\n",
      "0.9835836373774753\n",
      "0.9174180387396124\n",
      "0.36746883070914516\n",
      "0.9762866492138619\n",
      "0.8766874355074004\n",
      "0.933136668311764\n",
      "0.9486693931609567\n",
      "0.756436122350532\n",
      "0.9129822372883248\n",
      "0.8878696084425075\n",
      "0.9799512612133534\n",
      "0.8709644193922347\n",
      "0.9343246333968304\n",
      "0.11505365120445805\n",
      "0.8998930063533701\n",
      "0.3586360831726489\n",
      "0.9614552262879615\n",
      "0.7794780898062946\n",
      "0.9788489996295029\n",
      "0.9708929386311873\n",
      "0.9526160847762196\n",
      "0.9856001587486938\n",
      "0.9690530110899087\n",
      "0.30549749703003204\n",
      "0.9911180371231254\n",
      "0.9377328636541646\n",
      "0.2797915086400543\n",
      "0.9526580456495077\n",
      "0.976716735119003\n",
      "0.7191403915661505\n",
      "0.9742401892365179\n",
      "0.991263351444032\n",
      "0.7279961143828164\n",
      "0.9622290830109591\n",
      "0.9862532035120855\n",
      "0.9548322382975146\n",
      "0.9525887474969741\n",
      "0.9554857569188913\n",
      "0.8763052489824452\n",
      "0.9757439976859354\n",
      "0.43222211951527423\n",
      "0.9719830530490803\n",
      "0.9761399020234787\n",
      "0.9164459572419568\n",
      "0.978943609564403\n",
      "0.9714079593576145\n",
      "0.9401344151673087\n",
      "0.9783764906474114\n",
      "0.9563749974754153\n",
      "0.9596170377842156\n",
      "0.9776238807755484\n",
      "0.989813719648272\n",
      "0.988079065818439\n",
      "0.9406183648940292\n",
      "0.9431030350637163\n",
      "0.986179542329736\n",
      "0.9754464887962216\n",
      "0.8163659932522722\n",
      "0.9197171199629576\n",
      "0.9046197415506338\n",
      "0.22947620421786252\n",
      "0.9533175154889759\n",
      "0.2814192742151255\n",
      "0.9689479396124142\n",
      "0.9662496227058534\n",
      "0.9565823902659896\n",
      "0.9572418093543696\n",
      "0.8947235775215185\n",
      "0.8839289967205811\n",
      "0.9002856730517786\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The iou should be about 67%\n",
    "'''\n",
    "avg_iou = 0\n",
    "for line in lines:\n",
    "    input_img = load_input(line[0])\n",
    "    output = model.predict(input_img).transpose(0,3,1,2)\n",
    "    cur_iou = bbox_iou(get_box(output),line[1])\n",
    "    print(cur_iou)\n",
    "    avg_iou+= cur_iou\n",
    "avg_iou = avg_iou/len(lines)\n",
    "print(avg_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 2\n",
    "In this section, you need to convert the model into a model without batch normalization layers. The output of two model should be the same. Then you are required to quantize the model without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_bn = tf.keras.models.Sequential(\n",
    "    [\n",
    "    #first dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(48,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #second dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(96,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #third dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(192,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #fourth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(384,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #fifth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(512,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #output\n",
    "    layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write down the code to absorb bn layer into conv layer and maintain the same output as the original model. (please refer to HW2 Q4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_bn.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = load_input('images/2.jpg')\n",
    "output = model_no_bn.predict(input_img).transpose(0,3,1,2)\n",
    "get_box(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on the model_no_bn quantize the weights to 16 bits, 8 bits respectively.\n",
    "\n",
    "The requirement of quantization is given below:\n",
    "\n",
    "* For each layer's weights, set the upper bound as the minimum 2^n which is larger than the maximum value of unsigned weights. (eg: if the maximum value is 4.2375 and the minimum value is -7.83421, then the upper bound is 2^3 = 8)\n",
    "\n",
    "* Note that for each layer, the distribution of weights could be different.\n",
    "\n",
    "* The sign takes one bit. For example, if the upper bound is 8 and 5 bits is given for floating part, it actually takes 9 bits.\n",
    "\n",
    "* Do not quantize the bias!\n",
    "\n",
    "and get the accuracy report\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You should report the average IoU for each quantized model you get\n",
    "'''\n",
    "avg_iou = 0\n",
    "for line in lines:\n",
    "    input_img = load_input(line[0])\n",
    "    output = model_no_bn.predict(input_img).transpose(0,3,1,2)\n",
    "    avg_iou+= bbox_iou(get_box(output),line[1])\n",
    "avg_iou = avg_iou/1000\n",
    "print (avg_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based on the model_no_bn\n",
    "\n",
    "Now you can quantize both weights and bias parts.\n",
    "\n",
    "Explore eight different combination of weights and parts and specify your methods' details, and get the accuracy report\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
