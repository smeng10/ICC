{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testset():\n",
    "    url = 'https://courses.engr.illinois.edu/ece498icc/sp2019/lab2_request_dataset.php'\n",
    "    values = {'request': 'testdata', 'netid':'smeng10', 'team':'msp'}\n",
    "    r = requests.post(url, data=values, allow_redirects=True)\n",
    "    filename = r.url.split(\"/\")[-1]\n",
    "    testset_id = filename.split(\".\")[0].split(\"_\")[-1]\n",
    "    with open(filename, 'wb') as f: \n",
    "        f.write(r.content)\n",
    "    return load_dataset(filename), testset_id\n",
    "\n",
    "def load_dataset(path):\n",
    "    num_img = 1000\n",
    "    with gzip.open(path, 'rb') as infile:\n",
    "        data = np.frombuffer(infile.read(), dtype=np.uint8).reshape(num_img, 784)\n",
    "    return data\n",
    "\n",
    "def send_result(pred, testset_id,latency):\n",
    "    url = 'https://courses.engr.illinois.edu/ece498icc/sp2019/lab2_request_dataset.php'\n",
    "    values = {'request': 'verify', \n",
    "              'netid':'smeng10', \n",
    "              'team':'msp', \n",
    "              'testset_id' : testset_id, \n",
    "              'prediction' : pred, \n",
    "              'latency': latency}\n",
    "    r = requests.post(url, data=values, allow_redirects=True)\n",
    "    return r\n",
    "\n",
    "def create_keras_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=5, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
    "    model.add(tf.keras.layers.MaxPooling2D(strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def keras_test(ckpt, test_img):\n",
    "    #KERAS checkpoint\n",
    "    if ckpt == \"FashionNet/\":\n",
    "        model = create_keras_model()\n",
    "    elif ckpt == \"FashionNetModified/\":\n",
    "        model = create_keras_model_modified()\n",
    "    elif ckpt == \"FashionNetMobile/\":\n",
    "        model = create_keras_model_mobilnet()\n",
    "    else: raise KeyError\n",
    "    model.load_weights(ckpt)\n",
    "    \n",
    "    start = time.time()\n",
    "    pred = model.predict(test_img)\n",
    "    end = time.time()\n",
    "    \n",
    "    pred = ''.join(list(map(lambda x: str(x.argmax()),pred)))\n",
    "    return pred,calc_latency(start,end)\n",
    "\n",
    "def autotest(ckpt = \"all\"):\n",
    "    if ckpt == \"all\":\n",
    "        autotest(ckpt = \"FashionNet/\")\n",
    "        autotest(ckpt = \"FashionNetModified/\")\n",
    "        autotest(ckpt = \"FashionNetMobile/\")\n",
    "        return\n",
    "    data = get_testset()\n",
    "    imgs = data[0].reshape((data[0].shape[0], 28, 28, 1))/255.0\n",
    "    #test keras\n",
    "    pred, latency = keras_test(ckpt,imgs)\n",
    "    r = send_result(pred=pred, testset_id=data[1], latency=latency)\n",
    "    acc = int(r.text)/1000\n",
    "    Score = acc / (5 * latency)\n",
    "    print(f'checkpoint {ckpt} score is {Score}, its accuracy is {acc}, latency is {latency}')\n",
    "    \n",
    "def calc_latency(start,end):\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Latency evaluation of your FashionNet in lab2 running on Raspberry Pi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = autotest(ckpt=\"FashionNet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Implement a modified FashionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model_modified():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=5, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
    "    model.add(tf.keras.layers.MaxPooling2D(strides=2))\n",
    "    model.add(tf.keras.layers.DepthwiseConv2D(kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.SeparableConv2D(filters=3, kernel_size=1, padding='valid', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = create_keras_model_modified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#history = new_model.fit(train_images, train_labels, validation_split=0.1, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.save_weights(filepath='FashionNetModified/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autotest(ckpt=\"FashionNetModified/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Explore your own design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model_mobilnet():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Conv2D(3, (3, 3), strides=(1, 1), padding='same', activation=tf.nn.relu6, input_shape=(28, 28, 1)),\n",
    "    \n",
    "    keras.layers.DepthwiseConv2D((3, 3), depth_multiplier=1, strides=(1, 1), padding='same', activation=tf.nn.relu6),\n",
    "    keras.layers.Conv2D(8, (1, 1), strides=(1, 1), padding='same', activation=tf.nn.relu6),\n",
    "    keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.DepthwiseConv2D((3, 3), depth_multiplier=1, strides=(2, 2), padding='same', activation=tf.nn.relu6),\n",
    "    keras.layers.Conv2D(16, (1, 1), strides=(1, 1), padding='valid', activation=tf.nn.relu6),\n",
    "    keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.DepthwiseConv2D((3, 3), depth_multiplier=1, strides=(2, 2), padding='same', activation=tf.nn.relu6),\n",
    "    keras.layers.Conv2D(32, (1, 1), strides=(1, 1), padding='valid', activation=tf.nn.relu6),\n",
    "    keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.DepthwiseConv2D((3, 3), depth_multiplier=1, strides=(2, 2), padding='same', activation=tf.nn.relu6),\n",
    "    keras.layers.Conv2D(16, (1, 1), strides=(1, 1), padding='valid', activation=tf.nn.relu6),\n",
    "    keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    \n",
    "#     keras.layers.DepthwiseConv2D((3, 3), depth_multiplier=1, strides=(2, 2), padding='same', activation=tf.nn.relu6),\n",
    "#     keras.layers.Conv2D(8, (1, 1), strides=(1, 1), padding='valid', activation=tf.nn.relu6),\n",
    "#     keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5),\n",
    "#     keras.layers.Dropout(0.1),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu6),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu6),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = create_keras_model_mobilnet()\n",
    "# new_model.compile(optimizer='adam', \n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = new_model.fit(train_images, train_labels, validation_split=0.1, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model.save_weights(filepath='FashionNetMobile/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotest(ckpt='FashionNetMobile/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 3)         78        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 12, 12, 3)         84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 3)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 108)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10900     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 16,622\n",
      "Trainable params: 16,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_keras_model_modified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a2d3975c1fd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautotest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-18857f5f7abe>\u001b[0m in \u001b[0;36mautotest\u001b[1;34m(ckpt)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m#test keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msend_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestset_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-18857f5f7abe>\u001b[0m in \u001b[0;36mkeras_test\u001b[1;34m(ckpt, test_img)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mkeras_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FashionNet/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mkeras_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FashionNetModified/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mkeras_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FashionNetMobile/\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-18857f5f7abe>\u001b[0m in \u001b[0;36mkeras_test\u001b[1;34m(ckpt, test_img)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_keras_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"FashionNetModified/\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_keras_model_modified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"FashionNetMobile/\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_keras_model_mobilnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_keras_model_modified' is not defined"
     ]
    }
   ],
   "source": [
    "autotest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
